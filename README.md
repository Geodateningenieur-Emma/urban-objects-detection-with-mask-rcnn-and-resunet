<h3 align="left">Pre-train globally but fine-tune and apply locally</h3>

Open global datasets often fall short of meeting the precision requirements for local applications. To address this, we propose a pipeline that integrates extensive publicly available annotated datasets from around the world to train a base model, which can then be fine-tuned using a limited set of locally sourced samples. This approach allows for the generation of customised data, over which full control can be maintained, thereby enhancing local accuracy. Since deep learning models, utilizing various segmentation approaches, demonstrate differing levels of effectiveness in extracting urban objects such as buildings, in our paper [Local Evaluation of Large-scale Remote Sensing Machine Learning-generated Building and Road Dataset: The Case of Rwanda](https://link.springer.com/article/10.1007/s41064-024-00297-9), we explored [ResUNet](https://arxiv.org/abs/1711.10684) and [Mask Râ€‘CNN](https://github.com/matterport/Mask_RCNN) to examine the performance variations across distinct building detection methodologies: bottom-up, end-to-end, and a hybrid approach combining the two. The shapes generated by our models were then compared to the ones provided by Microsoft's and Google's global datasets, allowing for a comprehensive evaluation of performance and accuracy in the local context.  

<h3 align="left"> Installation</h3>

<p align="left">
</p>

