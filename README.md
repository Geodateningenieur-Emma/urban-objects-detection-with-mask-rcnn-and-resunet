Utilising large open global datasets often presents challenges in meeting local precision requirements. To address this, our framework combines extensive publicly available annotated global datasets with a limited set of locally sourced samples, allowing us to generate and fine-tune our own data, over which we maintain full control to better meet local accuracy needs. Since deep learning models, utilizing various segmentation approaches, demonstrate differing levels of effectiveness in extracting urban objects such as buildings. In our paper [Local Evaluation of Large-scale Remote Sensing Machine Learning-generated Building and Road Dataset: The Case of Rwanda](https://link.springer.com/article/10.1007/s41064-024-00297-9), we employed ResUNet and Mask Râ€‘CNN to examine the performance variations across distinct building detection methodologies: bottom-up, end-to-end, and a hybrid approach combining the two. The shapes generated by our models were then compared to the ones provided by Microsoft's and Google's global datasets, allowing for a comprehensive evaluation of performance and accuracy in the local context.  

<h3 align="left"></h3>
<p align="left">
</p>

